#summary Ideas and Suggestions for Research and Engineering Projects Involving Semantic Vectors

= Ideas =

There are many natural ideas and suggestions for things to try with SemanticVectors. This page is meant to be a starting point. Feel free to add new ideas or comment on existing ones. Many ideas start as discussions in the [https://groups.google.com/forum/?fromgroups#!forum/semanticvectors mailing list]. Some ideas turn into engineering tasks and may eventually be tracked at [https://code.google.com/p/semanticvectors/issues/list Issues].

== Engineering TODOs and Suggestions ==

 * Update to support Lucene 4.0 integration (see LuceneCompatibility).
 * Make the project work with Maven (see also [https://groups.google.com/forum/#!topic/semanticvectors/qCy0PaL7Nuo Maven artifact discussion]).
 * Make a couple of small UIs for demos (Swing client, simple Web client).

These are things Dominic hopes to get round to. Any other engineer who jumps in before me and tackles any of these successfully could be paid in [http://linkedin.com LinkedIn] endorsements, letters of reference, beer, chocolate - you choose.

== Incremental Indexing ==

This has been requested many times for practical reasons, and is a natural scientific question to ask of many of the algorithms used to reduce dimensions, and for learning in general.

Implementing incremental index updates for semantic vectors should be relatively easy: the algorithms would be fast, but issues related to file-ownership and thread-safety could be a pain.

So far, SV indexing is fast enough for most users, so incremental indexing has not been prioritized yet. Other pressing scientific motivation might arise from:
  * Dated / time varying corpora (e.g., analyzing the evolution of a news story over time).
  * Modelling narrative and discourse (e.g., a user session, events in a novel).
  * _Suggestions welcome ..._
 
== Ontology Modelling and Mapping ==

There are many reasons for investigating the relationships between semantic vector models and formal ontology models including taxonomies, conceptual graphs, Cyc, RDF, Wikipedia relationships, etc.

PredicationBasedSemanticIndexing results on Medline have been very promising, so extending these investigations beyond the biomedical domain is a natural step. Are the semantically valid generalizations that would enable us to model standard relationships like "is a" and "part of" as vector operators in some relatively comprehensive framework?

== Composition with Real, Complex and Binary Vectors ==

SV supports TypedVectors, but many questions about how best to implement Vector Symbolic Architectures (VSAs) over each ground field remain.

This manifests itself in several ways, including:
  * What does it mean to "scale" a binary vector by a given real number "weight"?
  * Do we need Fast Fourier Transforms (FFTs) for binding with real vectors, or is there a way to make [PermutationSearch permutation] operators work appropriately?
  * Should complex vectors in cartesian and circular [http://semanticvectors.googlecode.com/svn/javadoc/latest-stable/pitt/search/semanticvectors/vectors/ComplexVector.Mode.html mode] be separated into separate classes? 

The work on 
[https://code.google.com/p/semanticvectors/source/browse/trunk/src/pitt/search/semanticvectors/VectorStoreOrthographical.java orhtographic vectors] has exposed some of the frailties behind our existing assumptions in a very positive way, because orthographic word vectors can be combined in VSAs over different ground fields and produce markedly different results.

== Modeling Continuous Variables ==

The distributional models used in semantic vector models are by nature continuous, but are learned from discrete signals (e.g., how many times did a particular term occur in a particular document?). It should be natural to express continuous signals as well (e.g., the date, and even temperature and humidity when a document was written).

More generally, there are many areas where "records" naturally include continuous variables rather than discrete textual symbols.

Are the positional techniques used in orthographic vectors useful here?

== Introduce more decomposition, clustering, classification algorithms ==

Many algorithms could be incorporated into SV, including Latent Dirichlet Analysis (LDA), SVD for complex vectors, SVMs for binary classification.

In some cases it's unclear what this means with binary vectors, which again poses interesting mathematical research challenges.

== Compare and contrast directional / positional vector indexing with n-gram models ==

Compare results from n-gram modelling with vector positional indexing, for smoothing, computational cost, etc. 

== Spelling Correction, Autosuggest, Autocomplete ==

This would be a natural application for orthographic vectors and positional term vectors. Can these techniques be used to supplement / improve existing text suggestion / correction algorithms?