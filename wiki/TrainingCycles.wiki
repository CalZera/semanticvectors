#summary Training a model in multiple cycles

The basic way in which SemanticVectors builds models is:
  # Create basic random vectors for each document.
  # Create term vectors by summing the basic document vectors the term occurs in.
  # Create new document vectors by summing the term vectors of the terms that occur in each document.

The point of training cycles is that the output of stage 3 can be fed back into stage 2 - we can use the computed document vectors as the basic document vectors for computing term vectors.

To take advantage of this functionality, use the `-trainingcycles` option to BuildIndex, e.g., `java pitt.search.semanticvectors.BuildIndex -trainingcycles 10 <LUCENE_INDEX>`.

The use of several training cycles was explored and published under the title ReflectiveRandomIndexing.

So far, this option only exists for the default indexes - we haven't implemented it yet for PositionalIndexes, PermutationSearch, or BilingualModels.